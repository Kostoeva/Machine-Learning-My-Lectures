{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Would YOU Have Survived the Titanic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](titanic.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before any fun begins, let us set up the stage with some imports. These import statements will bring the tools into the workspace that is this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For reading in the spreadsheet data\n",
    "import pandas as pd\n",
    "#For data manipulation\n",
    "import random\n",
    "import numpy as mp\n",
    "#For the real machine learning tricks\n",
    "from sklearn import datasets, svm, cross_validation, tree, preprocessing, metrics\n",
    "#For visualizing data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PANDAS: we will use read_csv from pandas to \"read\" in the data from the train csv file. The \"head\" call returns the first N rows, and N=5 by default. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv', index_col=None, na_values=['NA'])\n",
    "test_df = pd.read_csv('test.csv', index_col=None, na_values=['NA'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point of having a data scientist process data rather than a machine, is to prevent the plot of Terminator from coming true. Just kidding, we are rreally trying to stop the plot of iRobot from coming true. Ha. Ha. Ha.\n",
    "\n",
    "Okay, enough with the attempts at witty jokes.\n",
    "\n",
    "The REAL point of having a data scientist process the data is because a human can make better calls than a machine. YOU need to understand the data you are given and adapt your analysis of it based off of your own judgement. \n",
    "\n",
    "Therefore, here are the column heading meanings: \n",
    "   <li>survival - binary (0 = No, 1 = Yes)</li>\n",
    "   <li>class - passenger class (1 = 1st - upper, 2 = 2nd, 3 = 3rd)</li>\n",
    "   <li>name - passenger's name</li>\n",
    "   <li>sex - sex</li>\n",
    "   <li>age - age</li>\n",
    "   <li>sibsp - number of siblings/spouses aboard</li>\n",
    "   <li>parch - number of parents/children aboard</li>\n",
    "   <li>ticket - ticket number</li>\n",
    "   <li>fare - passenger fare</li>\n",
    "   <li>cabin - cabin</li>\n",
    "   <li>embarked - point of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)</li>\n",
    "   <li>boat - lifeboat (if survived)</li>\n",
    "   <li>body - body number (if did not survive and body was recovered)</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Before we do anything else, let us checkout the survival rate on the Titanic\n",
    "train_df['Survived'].mean()\n",
    "#Here, we just called the \"Survived\" column and took the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what does this mean? Only 38% of the passengers survived :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is time to think. What do we know about the early 20th century? \n",
    "\n",
    "Social classes! \n",
    "\n",
    "We know that 1st class areas on the Titanic were off limits to 2nd class and 3rd class passengers.  1st class passengers were the rich folks. 2nd class passengers were the middle-class people. 3rd class passengers bought the economy ticket to the cruise. I would guess that 1st class passengers would have had better chances at survival. Let's see if I am right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Here, \"groupby\" will group by values from column \"Pclass\" => group by class\n",
    "class_grouping = train_df.groupby('Pclass').mean()['Survived']\n",
    "class_grouping.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, looks like 63% survival rate beats 47% and 24%.\n",
    "\n",
    "Let us see what we can infer from the other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Group the survival rates by sex. Pull up the plot for an easier view.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's right. Titanic officers, by the good old tradition, prioritized women and children when lifeboat evacuations came about. Our statistical results clearly reflect the first part of this policy, as across all classes women were much more likely to survive than the men. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now, let us drop some features we deem to be less important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_combed_df = train_df.drop(['Name', 'PassengerId', 'SibSp', 'Parch', 'Ticket', 'Fare'], axis = 1)\n",
    "test_combed_df = test_df.drop(['Name', 'PassengerId', 'SibSp', 'Parch', 'Ticket', 'Fare'], axis = 1)\n",
    "train_combed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, much cleaner! \n",
    "\n",
    "Now, we can get back to the goal of the Kaggle competition - predicting whether someone will live or die - a binary output (0 = dead, 1 = survived)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Modeling, Predicting, and Solving"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Time to train a model and make predictions. We will first begin with a Logistic Regression Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Getting the data ready\n",
    "X_train = train_combed_df.drop(\"Survived\", axis = 1)\n",
    "Y_train = train_combed_df[\"Survived\"]\n",
    "\n",
    "X_test = test_combed_df.copy()\n",
    "X_train.shape, Y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "logRegModel = LogisticRegression()\n",
    "logRegModel.fit(X_train, Y_train)\n",
    "Y_pred = logRegModel.predict(X_test)\n",
    "acc_log = round(logRegModel.score(X_train, Y_train) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh no! What's wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of our data is missing - and these missing values will not be of much help in our data analysis. Thus, we will drop all NaN values with a simple command from the combed train set to keep the two matrices equal in size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "together_DA = train_combed_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".dropna()   removes the   NaN   values from every remaining column/feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "together_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Divide the dataset into a train and a test set (1) X_train and (2) Y_train.\n",
    "X_train = together_DA.drop(\"Survived\", axis = 1)\n",
    "Y_train = together_DA[\"Survived\"]\n",
    "\n",
    "X_test = test_combed_df.copy()\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try creating a logistic regression model once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "logRegModel = LogisticRegression()\n",
    "logRegModel.fit(X_train, Y_train)\n",
    "Y_pred = logRegModel.predict(X_test)\n",
    "acc_log = round(logRegModel.score(X_train, Y_train) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](blob.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WHAT'S WRONG NOW?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](confused_cat.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we are trying to perform math on words - notice the contents of the \"Sex,\" \"Cabin,\" and \"Embarked\" columns - not numbers, are they? We take the easy way for the \"Cabin\" and \"Embarked\" columns for now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_bare = together_DA.drop(['Cabin', \"Embarked\"], axis = 1)\n",
    "X_train_bare.head()\n",
    "\n",
    "X_test_DA = X_test.dropna()\n",
    "X_test_bare = X_test_DA.drop(['Cabin', \"Embarked\"], axis = 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Alright, now we will convert the Sex feature to a numerical system where female = 1 and male = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined = [X_train_bare, X_test_bare]\n",
    "\n",
    "for dataset in combined:\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Split the data into (1) X_train_bare and (2) Y_train_bare sets to train the features against the survival outcomes.\n",
    "Y_train_bare = X_train_bare[\"Survived\"]\n",
    "X_train_bare = X_train_bare.drop([\"Survived\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now we can go ahead and create a logistic regression model.\n",
    "\n",
    "Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "logRegModel = LogisticRegression()\n",
    "logRegModel.fit(X_train_bare, Y_train_bare)\n",
    "Y_pred = logRegModel.predict(X_test_bare)\n",
    "acc_log = round(logRegModel.score(X_train_bare, Y_train_bare) * 100, 2)\n",
    "\n",
    "print(\"The accuracy of our model is \")\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Model 2: Support Vector Machines (aka SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SVC\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(X_train_bare, Y_train_bare)\n",
    "Y_pred = svc.predict(X_test_bare)\n",
    "acc_svc = round(svc.score(X_train_bare, Y_train_bare) * 100, 2)\n",
    "\n",
    "print(\"The accuracy of our model is \")\n",
    "acc_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3: Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Linear SVC\n",
    "\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(X_train_bare, Y_train_bare)\n",
    "Y_pred = linear_svc.predict(X_test_bare)\n",
    "acc_linear_svc = round(linear_svc.score(X_train_bare, Y_train_bare) * 100, 2)\n",
    "acc_linear_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 4: K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train_bare, Y_train_bare)\n",
    "Y_pred = knn.predict(X_test_bare)\n",
    "acc_knn = round(knn.score(X_train_bare, Y_train_bare) * 100, 2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 5: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train_bare, Y_train_bare)\n",
    "Y_pred = random_forest.predict(X_test_bare)\n",
    "random_forest.score(X_train_bare, Y_train_bare)\n",
    "acc_random_forest = round(random_forest.score(X_train_bare, Y_train_bare) * 100, 2)\n",
    "acc_random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 6: Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Decision Tree Classifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train_bare, Y_train_bare)\n",
    "Y_pred = decision_tree.predict(X_test_bare)\n",
    "acc_decision_tree = round(decision_tree.score(X_train_bare, Y_train_bare) * 100, 2)\n",
    "acc_decision_tree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
